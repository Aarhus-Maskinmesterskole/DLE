# ğŸ§ª Ã˜velse 3: MQTT Sparkplug B â€“ OpsÃ¦tning og publish/subscribe

## ğŸ¯ FormÃ¥l
FormÃ¥let med denne Ã¸velse er at give dig en grundig og praktisk introduktion til **MQTT Sparkplug B**, en industriel kommunikationsstandard som bygger oven pÃ¥ MQTT og tilfÃ¸jer vigtig semantik, struktur og metadata. Hvor almindelig MQTT kun definerer transporten af data, sikrer Sparkplug B, at alle parter ogsÃ¥ forstÃ¥r dataens betydning â€“ dvs. semantisk interoperabilitet.

Denne Ã¸velse vil give dig:
- Indblik i, hvordan Sparkplug B skaber en mere robust og struktureret mÃ¥de at sende og modtage data pÃ¥ i IIOT-miljÃ¸er
- Praktisk erfaring med opsÃ¦tning af en Sparkplug-kompatibel MQTT-broker
- Evnen til at publicere og abonnere pÃ¥ Sparkplug-topics med korrekt emnehierarki og payload-struktur
- TrÃ¦ning i at analysere og fortolke strukturerede Sparkplug-payloads og identificere enheder, sensorer, datatyper og metadata

---

## ğŸ› ï¸ ForudsÃ¦tninger
FÃ¸r du gÃ¥r i gang, skal du have:
- GennemfÃ¸rt Ã˜velse 1 og 2 og have forstÃ¥else for MQTT og OPC UA
- Installeret Docker **eller** adgang til en MQTT-broker med Sparkplug B-understÃ¸ttelse (fx HiveMQ, Chariot, Mosquitto med Sparkplug-support)
- En MQTT-klient klar â€“ fx Node-RED, MQTT.fx eller Sparkplug-kompatible scripts

---

## ğŸ“¦ Hvad er Sparkplug B?
Sparkplug B er en standard, udviklet af Eclipse Foundation, som strukturerer MQTT-topics og payloads med:
- Faste topic-formater
- Indlejret metadata
- Automatisk identifikation af devices og metrics
- Anvendelse af fÃ¸dsels-/dÃ¸dsbeskeder (birth/death)

Et typisk Sparkplug-topic ser sÃ¥dan ud:
```
spBv1.0/<GroupID>/<MessageType>/<EdgeNodeID>/<DeviceID>
```

### ğŸ“‹ Typer af Sparkplug-meddelelser
- `NBIRTH`: Node er online og sender initial konfiguration
- `DBIRTH`: Device er online og sender initial data
- `DDATA`: Almindelig datameddelelse (periodisk eller event-drevet)
- `NDEATH` / `DDEATH`: Signalerer at node eller device er offline

Payload bestÃ¥r typisk af:
```json
{
  "metrics": [
    {
      "name": "temperature",
      "value": 22.4,
      "type": "float",
      "unit": "Â°C"
    }
  ],
  "seq": 1,
  "timestamp": 1685500000000
}
```

---

## ğŸ”§ Praktisk â€“ Trin-for-trin

### 1. Start en Sparkplug-kompatibel broker
Hvis du ikke har en broker kÃ¸rende:
```bash
docker run -it -p 1883:1883 -p 9001:9001 eclipse/mosquitto
```
Hvis du har adgang til HiveMQ eller anden broker med Sparkplug-plugin, brug denne.

### 2. Udforsk Sparkplug-topics og payloads
- Brug MQTT.fx eller MQTT Explorer til at abonnere pÃ¥:
```
spBv1.0/#
```
- Observer hvordan emnerne er struktureret og hvordan data organiseres som `metrics`
- Brug JSON Viewer til at lÃ¦se payloads â€“ bemÃ¦rk `unit`, `type`, `source`, `seq` og `timestamp`

### 3. SimulÃ©r NBIRTH-meddelelse i Node-RED
- Lav en `inject` node, der sender fÃ¸lgende JSON-payload:
```json
{
  "metrics": [
    { "name": "temperature", "value": 22.4, "type": "float", "unit": "Â°C" },
    { "name": "humidity", "value": 58, "type": "int", "unit": "%" }
  ],
  "seq": 1,
  "timestamp": 1685500000000
}
```
- Brug en `JSON` node og forbind den til `mqtt out`
- Udfyld emne som: `spBv1.0/demo/NBIRTH/Edge_1/Device_A`

### 4. Opbyg dit eget Sparkplug-flow
- Brug `function` node til at danne struktureret Sparkplug-payload dynamisk
- KombinÃ©r med `inject` og evt. `random`-generator til at simulere sensor-data
- Udfyld `mqtt-out` emne med korrekt format: `spBv1.0/demo/DDATA/Edge_1/Device_A`
- TilfÃ¸j `debug` og evt. `ui_table` til at visualisere modtagne metrics

### 5. Valgfrit: KombinÃ©r med tidligere OPC UA-data
- Brug output fra Ã˜velse 2 og pak det om i Sparkplug-format
- Det viser hvordan interoperabilitet mellem OPC UA og Sparkplug kan se ud

---

## ğŸ“‹ Refleksion
- Hvordan adskiller Sparkplug B sig fra almindelig MQTT?
- Hvilke fordele ser du ved fast struktur og standardiserede payloads?
- Hvordan understÃ¸tter Sparkplug interoperabilitet og forstÃ¥elighed i stÃ¸rre IIOT-systemer?
- Kunne du forestille dig at bruge dette i praksis â€“ og i sÃ¥ fald, hvor?

> ğŸ’¡ Du kommer i nÃ¦ste Ã¸velse til at designe din egen datamodel baseret pÃ¥ den erfaring du fÃ¥r her â€“ og vÃ¦lge, hvorda
